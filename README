# ğŸ§ GMM-Based Music Genre Classifier

This project uses Gaussian Mixture Models (GMMs) to classify music into 10 genres 
using MFCC audio features from the GTZAN dataset.

## ğŸ“Œ Features
- MFCC-based audio analysis
- One GMM per genre (class-conditional modeling)
- Classification via log-likelihood
- 70% accuracy on GTZAN

## ğŸš€ Project Structure
<folder tree>

## ğŸ“Š Results
- Confusion matrix
- Sample predictions

## ğŸ”§ Tech Stack
Python, Librosa, Scikit-learn, NumPy, Matplotlib

## ğŸ“ Theory
GMMs model a data distribution as a mixture of multiple Gaussian densities, which makes them extremely effective for audio because real-world audio features (MFCCs, spectral coefficients) are highly variable and multi-modal.

Different sounds (phonemes, instruments, timbres) produce clusters of feature vectors in different regions of the feature space.
A single Gaussian cannot capture this complexity, but a mixture of Gaussians can approximate any continuous density. This lets GMMs:

âœ… 1. Capture Multi-Modal Structure

Audio frames from different sound sources or phonemes form different â€œcloudsâ€ in feature space.
GMMs naturally model these using multiple components, each specializing in one pattern.

âœ… 2. Handle Frame-Level Variability

Audio features change every 10â€“20 ms.
GMMs assume each frame is generated from one latent Gaussian component â†’ perfect for frame-based modeling like speech and music.

âœ… 3. Smooth, Continuous Probability Estimation

Gaussian functions give smooth boundaries and soft assignments, which works better than hard clustering (K-means) for noisy, overlapping audio features.

âœ… 4. Mathematical Convenience

GMMs integrate perfectly with algorithms used in audio:

EM algorithm â†’ easy parameter learning

HMM + GMM â†’ classical backbone of speech recognition

Efficient likelihood computation for classification
